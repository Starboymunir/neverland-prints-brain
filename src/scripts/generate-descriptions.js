/**
 * Neverland Prints â€” AI Description Generator (OpenAI)
 * =====================================================
 * Generates unique AI descriptions for all products using GPT-4o-mini.
 *
 * Strategy: BATCHED text-only prompts (50 products per API call)
 *   - Reduces 101k individual calls to ~2,020 batch calls
 *   - GPT-4o-mini: ~$2-3 for 101k products
 *   - High concurrency (10 parallel requests) = very fast
 *
 * Pipeline:
 *   Phase 1: GPT-4o-mini generates descriptions â†’ stored in Supabase
 *   Phase 2: Rich HTML built and pushed to Shopify products
 *
 * Usage:
 *   node src/scripts/generate-descriptions.js                    # full run
 *   node src/scripts/generate-descriptions.js --limit=100        # test batch
 *   node src/scripts/generate-descriptions.js --shopify-only     # skip AI, just update Shopify HTML
 *   node src/scripts/generate-descriptions.js --gemini-only      # skip Shopify, just generate descriptions
 *   node src/scripts/generate-descriptions.js --batch-size=30    # custom batch size
 *   node src/scripts/generate-descriptions.js --concurrency=5    # AI request concurrency
 */

require("dotenv").config();
const OpenAI = require("openai");
const { createClient } = require("@supabase/supabase-js");
const config = require("../config");

// Catch unhandled errors
process.on("unhandledRejection", (err) => { console.error("Unhandled rejection:", err); process.exit(1); });
process.on("uncaughtException", (err) => { console.error("Uncaught exception:", err); process.exit(1); });

// â”€â”€ CLI args â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const args = process.argv.slice(2);
const getArg = (n) => { const a = args.find(x => x.startsWith(`--${n}=`)); return a ? a.split("=")[1] : null; };
const hasFlag = (n) => args.includes(`--${n}`);

const LIMIT = parseInt(getArg("limit") || "0", 10); // 0 = all
const BATCH_SIZE = parseInt(getArg("batch-size") || "50", 10);
const AI_CONCURRENCY = parseInt(getArg("concurrency") || "10", 10);
const SHOPIFY_CONCURRENCY = parseInt(getArg("shopify-concurrency") || "8", 10);
const SHOPIFY_ONLY = hasFlag("shopify-only");
const GEMINI_ONLY = hasFlag("gemini-only"); // kept for CLI compat, means "AI only"
const DRY_RUN = hasFlag("dry-run");

// â”€â”€ Services â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_SERVICE_KEY);
const SHOP = process.env.SHOPIFY_STORE_DOMAIN;
const TOKEN = process.env.SHOPIFY_ADMIN_API_TOKEN;
const API_VER = config.shopify.apiVersion || "2024-10";
const BASE = `https://${SHOP}/admin/api/${API_VER}`;

const sleep = (ms) => new Promise(r => setTimeout(r, ms));

// â”€â”€ OpenAI Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let openai = null;

function initOpenAI() {
  if (!process.env.OPENAI_API_KEY) throw new Error("OPENAI_API_KEY not set in .env");
  openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  console.log("âœ… OpenAI GPT-4o-mini initialized");
}

// â”€â”€ Batch Description Generator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const SYSTEM_PROMPT = `You are a world-class art curator writing product descriptions for "Neverland Prints", a premium fine art print store.

RULES:
- Write EXACTLY 1-2 sentences per artwork (STRICT MAX 180 characters per description)
- Capture the artistic essence, visual mood, and period/style
- Sound refined, gallery-worthy, and enticing to art buyers
- Do NOT mention printing, paper, framing, or shipping â€” only the artwork itself
- Do NOT repeat the artwork title or artist name in the description
- If you don't know the artwork, write something evocative based on the title and artist's known style

Return ONLY a JSON object with an "items" array. Each element: {"i": <1-based index>, "d": "<description under 180 chars>"}
Example: {"items": [{"i": 1, "d": "A hauntingly beautiful meditation on solitude, rendered in luminous watercolors that shimmer with quiet emotion."}]}`;

/**
 * Generate descriptions for a batch of products via GPT-4o-mini.
 * @param {Array} batch - array of {title, artist} objects
 * @returns {Map<number, string>} - map of 0-based idx â†’ description
 */
async function generateBatch(batch, retries = 3) {
  const artworkList = batch
    .map((b, i) => `${i + 1}. "${b.title}" by ${b.artist}`)
    .join("\n");

  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      const response = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: SYSTEM_PROMPT },
          { role: "user", content: artworkList },
        ],
        temperature: 0.7,
        max_tokens: 4096,
        response_format: { type: "json_object" },
      });

      const text = response.choices[0]?.message?.content?.trim() || "";

      // Parse JSON response
      let parsed;
      try {
        const obj = JSON.parse(text);
        // Handle: {"items": [...]}, {"descriptions": [...]}, or direct array
        parsed = obj.items || obj.descriptions || obj.results || obj.data || (Array.isArray(obj) ? obj : Object.values(obj).find(v => Array.isArray(v)) || []);
      } catch {
        const cleaned = text
          .replace(/^```json\s*/i, "")
          .replace(/^```\s*/i, "")
          .replace(/\s*```$/i, "")
          .trim();
        const obj = JSON.parse(cleaned);
        parsed = obj.items || obj.descriptions || obj.results || (Array.isArray(obj) ? obj : Object.values(obj).find(v => Array.isArray(v)) || []);
      }

      if (!Array.isArray(parsed) || parsed.length === 0) {
        throw new Error(`Invalid response format: ${text.slice(0, 100)}`);
      }

      // Map results back to batch indices
      const results = new Map();
      for (const item of parsed) {
        const idx = (item.i || item.idx || item.index) - 1; // Convert 1-based to 0-based
        const desc = item.d || item.desc || item.description || "";
        if (idx >= 0 && idx < batch.length && desc) {
          results.set(idx, desc.slice(0, 300)); // Cap at 300 chars
        }
      }

      return results;
    } catch (err) {
      const isRateLimit = err.status === 429 || err.message?.includes("429") || err.message?.includes("rate");
      if (isRateLimit) {
        const waitTime = Math.min(attempt * 10, 60);
        console.log(`   â³ Rate limited â€” waiting ${waitTime}s (attempt ${attempt}/${retries})`);
        await sleep(waitTime * 1000);
        continue;
      }
      if (attempt < retries) {
        console.log(`   âš ï¸ OpenAI error (attempt ${attempt}): ${(err.message || "").slice(0, 80)} â€” retrying...`);
        await sleep(2000 * attempt);
        continue;
      }
      console.error(`   âŒ Batch failed after ${retries} attempts: ${(err.message || "").slice(0, 100)}`);
      return new Map();
    }
  }
  return new Map();
}

// â”€â”€ Shopify API Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function shopifyUpdate(productId, bodyHtml, retries = 3) {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      const res = await fetch(`${BASE}/products/${productId}.json`, {
        method: "PUT",
        headers: {
          "Content-Type": "application/json",
          "X-Shopify-Access-Token": TOKEN,
        },
        body: JSON.stringify({ product: { id: productId, body_html: bodyHtml } }),
      });

      if (res.status === 429) {
        const wait = parseFloat(res.headers.get("Retry-After") || "2");
        await sleep(wait * 1000);
        continue;
      }

      if (!res.ok) {
        const body = await res.text();
        throw new Error(`HTTP ${res.status}: ${body.slice(0, 100)}`);
      }

      return true;
    } catch (err) {
      if (attempt < retries) {
        await sleep(1000 * attempt);
        continue;
      }
      throw err;
    }
  }
  return false;
}

// â”€â”€ Build Rich HTML Description â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function buildProductHtml(asset, variants = []) {
  const artistName = asset.artist || "Unknown Artist";
  const aiDesc = asset.description || "";

  // Size list
  const sizes = variants.length > 0
    ? variants.map(v => `${v.label}: ${v.width_cm}Ã—${v.height_cm} cm`).join(" Â· ")
    : "";

  // Quality tier text
  const qualityText = asset.quality_tier === "high"
    ? "museum-quality"
    : "gallery-quality";

  let html = `<div class="np-description">`;

  // AI-generated curator note (unique per product)
  if (aiDesc) {
    html += `<p class="np-curator">${aiDesc}</p>`;
  }

  // Print quality section
  html += `<p>This ${qualityText} giclÃ©e reproduction by <strong>${artistName}</strong> is printed on premium 310gsm cotton-rag archival paper using 12-colour pigment-based inks rated for 200+ years of lightfastness.</p>`;

  // Available sizes
  if (sizes) {
    html += `<p><strong>Available sizes:</strong> ${sizes}</p>`;
  }

  // Trust signals
  html += `<ul class="np-features">`;
  html += `<li>ğŸ¨ Museum-grade archival paper (310gsm cotton rag)</li>`;
  html += `<li>ğŸ–¨ï¸ 12-colour giclÃ©e pigment inks</li>`;
  html += `<li>â³ 200+ year lightfastness rating</li>`;
  html += `<li>ğŸ“¦ Ships flat in rigid protective packaging</li>`;
  html += `<li>ğŸ”„ 30-day satisfaction guarantee</li>`;
  html += `</ul>`;

  html += `</div>`;
  return html;
}

// â”€â”€ Concurrency limiter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function createPool(concurrency) {
  const queue = [];
  let running = 0;

  return function enqueue(fn) {
    return new Promise((resolve, reject) => {
      queue.push({ fn, resolve, reject });
      drain();
    });
  };

  function drain() {
    while (running < concurrency && queue.length > 0) {
      const { fn, resolve, reject } = queue.shift();
      running++;
      fn()
        .then(resolve)
        .catch(reject)
        .finally(() => { running--; drain(); });
    }
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PHASE 1: Generate AI Descriptions via OpenAI
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async function phase1_generateDescriptions() {
  console.log("\n" + "â•".repeat(60));
  console.log("ğŸ¤– PHASE 1: Generating AI Descriptions (GPT-4o-mini)");
  console.log("â•".repeat(60));

  initOpenAI();

  // Fetch assets without descriptions (cursor-based pagination for large datasets)
  console.log("\nğŸ“¦ Fetching assets without descriptions...");

  let allAssets = [];
  let lastId = null;
  const PAGE_SIZE = 1000;

  while (true) {
    let query = supabase
      .from("assets")
      .select("id, title, artist, quality_tier, ratio_class")
      .or("description.is.null,description.eq.")
      .order("id")
      .limit(PAGE_SIZE);

    if (lastId) {
      query = query.gt("id", lastId);
    }

    const { data, error } = await query;

    if (error) throw error;
    if (!data || data.length === 0) break;

    allAssets.push(...data);
    lastId = data[data.length - 1].id;

    if (allAssets.length % 10000 === 0) {
      console.log(`   ... fetched ${allAssets.length} so far`);
    }

    if (data.length < PAGE_SIZE) break;
    if (LIMIT > 0 && allAssets.length >= LIMIT) {
      allAssets = allAssets.slice(0, LIMIT);
      break;
    }
  }

  if (LIMIT > 0 && allAssets.length > LIMIT) {
    allAssets = allAssets.slice(0, LIMIT);
  }

  console.log(`   Found ${allAssets.length} assets needing descriptions`);

  if (allAssets.length === 0) {
    console.log("   âœ… All assets already have descriptions!");
    return;
  }

  if (DRY_RUN) {
    console.log("\nğŸƒ DRY RUN â€” would generate descriptions for:");
    allAssets.slice(0, 10).forEach(a => console.log(`   "${a.title}" by ${a.artist}`));
    if (allAssets.length > 10) console.log(`   ... and ${allAssets.length - 10} more`);
    return;
  }

  // Split into batches
  const batches = [];
  for (let i = 0; i < allAssets.length; i += BATCH_SIZE) {
    batches.push(allAssets.slice(i, i + BATCH_SIZE));
  }

  const estTokensIn = allAssets.length * 40;
  const estTokensOut = allAssets.length * 40;
  const estCost = ((estTokensIn * 0.15 + estTokensOut * 0.6) / 1_000_000).toFixed(2);

  console.log(`   Batches: ${batches.length} (${BATCH_SIZE} products each)`);
  console.log(`   Concurrency: ${AI_CONCURRENCY} parallel requests`);
  console.log(`   Est. cost: ~$${estCost} (GPT-4o-mini)`);
  console.log(`   Est. time: ~${Math.ceil(batches.length / AI_CONCURRENCY / 60 * 3)} min\n`);

  let totalGenerated = 0;
  let totalFailed = 0;
  const startTime = Date.now();

  // Process batches with concurrency pool
  const pool = createPool(AI_CONCURRENCY);
  const batchPromises = batches.map((batch, batchIdx) =>
    pool(async () => {
      // Prepare batch data
      const batchData = batch.map((asset) => ({
        title: asset.title || "Untitled",
        artist: asset.artist || "Unknown Artist",
      }));

      // Generate descriptions
      const results = await generateBatch(batchData);

      // Update Supabase
      let batchGenerated = 0;
      const updates = [];

      for (let i = 0; i < batch.length; i++) {
        const desc = results.get(i);
        if (desc) {
          updates.push({ id: batch[i].id, description: desc });
          batchGenerated++;
        }
      }

      // Batch update Supabase (individual updates since upsert requires full row)
      if (updates.length > 0) {
        const updatePromises = updates.map(u =>
          supabase.from("assets").update({ description: u.description }).eq("id", u.id)
        );
        const results = await Promise.all(updatePromises);
        const errs = results.filter(r => r.error);
        if (errs.length > 0) console.error(`   âŒ Supabase: ${errs.length} update errors`);
      }

      totalGenerated += batchGenerated;
      totalFailed += batch.length - batchGenerated;

      // Progress every 10 batches
      if ((batchIdx + 1) % 10 === 0 || batchIdx === batches.length - 1) {
        const elapsed = ((Date.now() - startTime) / 1000).toFixed(0);
        const pct = (((batchIdx + 1) / batches.length) * 100).toFixed(1);
        const rate = (totalGenerated / (elapsed || 1)).toFixed(1);
        console.log(
          `   ğŸ“ Batch ${batchIdx + 1}/${batches.length} | ` +
          `${totalGenerated} generated | ${totalFailed} failed | ` +
          `${pct}% | ${rate}/s | ${elapsed}s`
        );
      }
    })
  );

  await Promise.all(batchPromises);

  const totalTime = ((Date.now() - startTime) / 1000).toFixed(1);
  console.log(`\n   âœ… Phase 1 complete: ${totalGenerated} descriptions in ${totalTime}s`);
  if (totalFailed > 0) console.log(`   âš ï¸ ${totalFailed} failed â€” re-run to retry`);
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PHASE 2: Update Shopify Product HTML
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async function phase2_updateShopify() {
  console.log("\n" + "â•".repeat(60));
  console.log("ğŸ›ï¸  PHASE 2: Updating Shopify Product Descriptions");
  console.log("â•".repeat(60));

  // Fetch all synced assets with descriptions (cursor-based pagination)
  console.log("\nğŸ“¦ Fetching synced products with descriptions...");

  let assets = [];
  let lastId = null;
  const PAGE_SIZE = 1000;

  while (true) {
    let query = supabase
      .from("assets")
      .select("id, title, artist, description, quality_tier, ratio_class, shopify_product_id")
      .eq("shopify_status", "synced")
      .not("shopify_product_id", "is", null)
      .not("description", "is", null)
      .neq("description", "")
      .order("id")
      .limit(PAGE_SIZE);

    if (lastId) {
      query = query.gt("id", lastId);
    }

    const { data, error } = await query;

    if (error) throw error;
    if (!data || data.length === 0) break;

    assets.push(...data);
    lastId = data[data.length - 1].id;

    if (data.length < PAGE_SIZE) break;
    if (LIMIT > 0 && assets.length >= LIMIT) {
      assets = assets.slice(0, LIMIT);
      break;
    }
  }

  console.log(`   Found ${assets.length} products to update on Shopify`);

  if (assets.length === 0) {
    console.log("   âš ï¸ No products with descriptions ready for Shopify update");
    return;
  }

  if (DRY_RUN) {
    const sample = assets[0];
    const html = buildProductHtml(sample);
    console.log("\nğŸƒ DRY RUN â€” sample HTML:\n" + html);
    return;
  }

  // Fetch variants for all assets
  console.log("   Loading variant data...");
  const assetIds = assets.map(a => a.id);
  const variantsMap = new Map();

  for (let i = 0; i < assetIds.length; i += 500) {
    const chunk = assetIds.slice(i, i + 500);
    const { data: variants } = await supabase
      .from("asset_variants")
      .select("asset_id, label, width_cm, height_cm")
      .in("asset_id", chunk)
      .order("width_cm", { ascending: true });

    if (variants) {
      for (const v of variants) {
        if (!variantsMap.has(v.asset_id)) variantsMap.set(v.asset_id, []);
        variantsMap.get(v.asset_id).push(v);
      }
    }
  }

  console.log(`   Loaded variants for ${variantsMap.size} products\n`);

  // Update Shopify products with concurrency pool
  let updated = 0;
  let errors = 0;
  const startTime = Date.now();
  const pool = createPool(SHOPIFY_CONCURRENCY);

  const updatePromises = assets.map((asset) =>
    pool(async () => {
      const variants = variantsMap.get(asset.id) || [];
      const html = buildProductHtml(asset, variants);

      try {
        await shopifyUpdate(asset.shopify_product_id, html);
        updated++;
      } catch (err) {
        errors++;
        if (errors <= 5) {
          console.error(`   âŒ Product ${asset.shopify_product_id}: ${(err.message || "").slice(0, 80)}`);
        }
      }

      // Progress every 500
      if ((updated + errors) % 500 === 0) {
        const elapsed = ((Date.now() - startTime) / 1000).toFixed(0);
        const rate = (updated / (elapsed || 1)).toFixed(1);
        const pct = (((updated + errors) / assets.length) * 100).toFixed(1);
        console.log(
          `   ğŸ›ï¸  ${updated} updated | ${errors} errors | ${pct}% | ${rate}/s | ${elapsed}s`
        );
      }
    })
  );

  await Promise.all(updatePromises);

  const totalTime = ((Date.now() - startTime) / 1000).toFixed(1);
  console.log(`\n   âœ… Phase 2 complete: ${updated} Shopify products updated in ${totalTime}s`);
  if (errors > 0) console.log(`   âš ï¸ ${errors} errors â€” re-run to retry`);
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MAIN
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async function main() {
  console.log("\n" + "â•".repeat(60));
  console.log("ğŸ¨ NEVERLAND PRINTS â€” AI Description Generator");
  console.log("â•".repeat(60));
  console.log(`  Engine: OpenAI GPT-4o-mini`);
  console.log(`  Batch size: ${BATCH_SIZE} | AI concurrency: ${AI_CONCURRENCY}`);
  console.log(`  Shopify concurrency: ${SHOPIFY_CONCURRENCY}`);
  console.log(`  Limit: ${LIMIT || "ALL"} | Dry run: ${DRY_RUN ? "YES" : "NO"}`);
  console.log("â•".repeat(60));

  const overallStart = Date.now();

  if (!SHOPIFY_ONLY) {
    await phase1_generateDescriptions();
  }

  if (!GEMINI_ONLY) {
    await phase2_updateShopify();
  }

  const totalTime = ((Date.now() - overallStart) / 1000 / 60).toFixed(1);
  console.log("\n" + "â•".repeat(60));
  console.log(`ğŸ ALL DONE in ${totalTime} minutes`);
  console.log("â•".repeat(60) + "\n");
}

main().catch(err => {
  console.error("\nğŸ’¥ Fatal error:", err);
  process.exit(1);
});
